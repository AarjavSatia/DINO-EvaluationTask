submitit INFO (2022-07-15 00:27:33,142) - Starting with JobEnvironment(job_id=2497937, hostname=dgx061.scc.idea, local_rank=5(8), node=0(1), global_rank=5(8))
submitit INFO (2022-07-15 00:27:33,144) - Loading pickle: /student/zhanghao/code/DINO/logs/DINO/R50-MS4-2497937/2497937_submitted.pkl
Process group: 8 tasks, rank: 5
Not using distributed mode
Loading config file from config/DINO/DINO_4scale_convnext.py
[07/15 00:27:36.145]: git:
  sha: 22086830aaa6e065082bad56c0fdfe6928aacd5c, status: has uncommited changes, branch: main

[07/15 00:27:36.148]: Command: /home/zhanghao/miniconda3/envs/q2x/lib/python3.7/site-packages/submitit/core/_submit.py /student/zhanghao/code/DINO/logs/DINO/R50-MS4-%j
[07/15 00:27:36.153]: Full config saved to logs/DINO/R50-MS4-2497937/config_args_all.json
[07/15 00:27:36.154]: world size: 1
[07/15 00:27:36.156]: rank: 0
[07/15 00:27:36.158]: local_rank: 0
[07/15 00:27:36.159]: args: Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='convnext_xlarge_22k', backbone_dir='/student/zhanghao/pretrained/', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=1.0, coco_panoptic_path=None, coco_path='/student/zhanghao/coco17/', commad_txt='Command: run_with_submitit.py --timeout 3000 --job_name DINO --job_dir logs/DINO/R50-MS4-%j --ngpus 8 --nodes 1 -c config/DINO/DINO_4scale_convnext.py --coco_path /student/zhanghao/coco17/ --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0 backbone_dir=/student/zhanghao/pretrained/', config_file='config/DINO/DINO_4scale_convnext.py', cpus_per_task=16, dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], dataset_file='coco', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_url='file:///comp_robot/zhanghao/experiments/286b271945b349e4b545601f9d49f009_init', distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_number=100, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=12, eval=False, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2.0, gpu=5, hidden_dim=256, interm_loss_coef=1.0, job_dir='logs/DINO/R50-MS4-%j', job_name='DINO', local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[33, 45], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mail_type='ALL', mail_user='', mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', modelname='dino', multi_step_lr=False, ngpus=8, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, nodes=1, note='', num_classes=91, num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=10, onecyclelr=False, options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0, 'backbone_dir': '/student/zhanghao/pretrained/'}, output_dir='logs/DINO/R50-MS4-2497937', param_dict_type='default', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, qos=None, query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, requeue=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, start_epoch=0, test=False, timeout=3000, transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', unic_layers=0, use_checkpoint=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_dn=True, use_ema=False, weight_decay=0.0001, world_size=1)

Namespace(add_channel_attention=False, add_pos_value=False, amp=False, aux_loss=True, backbone='convnext_xlarge_22k', backbone_dir='/student/zhanghao/pretrained/', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5.0, box_attn_type='roi_align', clip_max_norm=0.1, cls_loss_coef=1.0, coco_panoptic_path=None, coco_path='/student/zhanghao/coco17/', commad_txt='Command: run_with_submitit.py --timeout 3000 --job_name DINO --job_dir logs/DINO/R50-MS4-%j --ngpus 8 --nodes 1 -c config/DINO/DINO_4scale_convnext.py --coco_path /student/zhanghao/coco17/ --options dn_scalar=100 embed_init_tgt=TRUE dn_label_coef=1.0 dn_bbox_coef=1.0 use_ema=False dn_box_noise_scale=1.0 backbone_dir=/student/zhanghao/pretrained/', config_file='config/DINO/DINO_4scale_convnext.py', cpus_per_task=16, dabdetr_deformable_decoder=False, dabdetr_deformable_encoder=False, dabdetr_yolo_like_anchor_update=False, data_aug_max_size=1333, data_aug_scale_overlap=None, data_aug_scales=[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], data_aug_scales2_crop=[384, 600], data_aug_scales2_resize=[400, 500, 600], dataset_file='coco', ddetr_lr_param=False, debug=False, dec_layer_number=None, dec_layers=6, dec_n_points=4, dec_pred_bbox_embed_share=True, dec_pred_class_embed_share=True, decoder_layer_noise=False, decoder_module_seq=['sa', 'ca', 'ffn'], decoder_sa_type='sa', device='cuda', dice_loss_coef=1.0, dilation=False, dim_feedforward=2048, dist_url='file:///comp_robot/zhanghao/experiments/286b271945b349e4b545601f9d49f009_init', distributed=False, dln_hw_noise=0.2, dln_xy_noise=0.2, dn_bbox_coef=1.0, dn_box_noise_scale=1.0, dn_label_coef=1.0, dn_label_noise_ratio=0.5, dn_labelbook_size=91, dn_number=100, dn_scalar=100, dropout=0.0, ema_decay=0.9997, ema_epoch=0, embed_init_tgt=True, enc_layers=6, enc_loss_coef=1.0, enc_n_points=4, epochs=12, eval=False, find_unused_params=False, finetune_ignore=None, fix_refpoints_hw=-1, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2.0, gpu=5, hidden_dim=256, interm_loss_coef=1.0, job_dir='logs/DINO/R50-MS4-%j', job_name='DINO', local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_backbone_names=['backbone.0'], lr_drop=11, lr_drop_list=[33, 45], lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mail_type='ALL', mail_user='', mask_loss_coef=1.0, masks=False, match_unstable_error=True, matcher_type='HungarianMatcher', modelname='dino', multi_step_lr=False, ngpus=8, nheads=8, nms_iou_threshold=-1, no_interm_box_loss=False, nodes=1, note='', num_classes=91, num_feature_levels=4, num_patterns=0, num_queries=900, num_select=300, num_workers=10, onecyclelr=False, options={'dn_scalar': 100, 'embed_init_tgt': True, 'dn_label_coef': 1.0, 'dn_bbox_coef': 1.0, 'use_ema': False, 'dn_box_noise_scale': 1.0, 'backbone_dir': '/student/zhanghao/pretrained/'}, output_dir='logs/DINO/R50-MS4-2497937', param_dict_type='default', pdetr3_bbox_embed_diff_each_layer=False, pdetr3_refHW=-1, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, qos=None, query_dim=4, random_refpoints_xy=False, rank=0, remove_difficult=False, requeue=False, resume='', return_interm_indices=[1, 2, 3], save_checkpoint_interval=1, save_log=False, save_results=False, seed=42, set_cost_bbox=5.0, set_cost_class=2.0, set_cost_giou=2.0, start_epoch=0, test=False, timeout=3000, transformer_activation='relu', two_stage_add_query_num=0, two_stage_bbox_embed_share=False, two_stage_class_embed_share=False, two_stage_default_hw=0.05, two_stage_keep_all_tokens=False, two_stage_learn_wh=False, two_stage_pat_embed=0, two_stage_type='standard', unic_layers=0, use_checkpoint=False, use_deformable_box_attn=False, use_detached_boxes_dec_out=False, use_dn=True, use_ema=False, weight_decay=0.0001, world_size=1)
_IncompatibleKeys(missing_keys=['norm0.weight', 'norm0.bias', 'norm1.weight', 'norm1.bias', 'norm2.weight', 'norm2.bias', 'norm3.weight', 'norm3.bias'], unexpected_keys=['norm.weight', 'norm.bias', 'head.weight', 'head.bias'])
[07/15 00:28:01.565]: number of params:371589822
[07/15 00:28:01.570]: params:
{
  "transformer.level_embed": 1024,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.0.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.0.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.0.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.0.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.0.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.1.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.1.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.1.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.1.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.1.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.2.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.2.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.2.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.2.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.2.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.3.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.3.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.3.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.3.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.3.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.4.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.4.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.4.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.4.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.4.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.weight": 65536,
  "transformer.encoder.layers.5.self_attn.sampling_offsets.bias": 256,
  "transformer.encoder.layers.5.self_attn.attention_weights.weight": 32768,
  "transformer.encoder.layers.5.self_attn.attention_weights.bias": 128,
  "transformer.encoder.layers.5.self_attn.value_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.value_proj.bias": 256,
  "transformer.encoder.layers.5.self_attn.output_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.output_proj.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.0.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.0.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.0.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.1.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.1.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.1.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.2.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.2.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.2.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.3.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.3.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.3.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.4.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.4.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.4.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.sampling_offsets.bias": 256,
  "transformer.decoder.layers.5.cross_attn.attention_weights.weight": 32768,
  "transformer.decoder.layers.5.cross_attn.attention_weights.bias": 128,
  "transformer.decoder.layers.5.cross_attn.value_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.value_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.output_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.output_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.decoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.0.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.0.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.0.layers.2.bias": 4,
  "transformer.decoder.class_embed.0.weight": 23296,
  "transformer.decoder.class_embed.0.bias": 91,
  "transformer.tgt_embed.weight": 230400,
  "transformer.enc_output.weight": 65536,
  "transformer.enc_output.bias": 256,
  "transformer.enc_output_norm.weight": 256,
  "transformer.enc_output_norm.bias": 256,
  "transformer.enc_out_bbox_embed.layers.0.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.0.bias": 256,
  "transformer.enc_out_bbox_embed.layers.1.weight": 65536,
  "transformer.enc_out_bbox_embed.layers.1.bias": 256,
  "transformer.enc_out_bbox_embed.layers.2.weight": 1024,
  "transformer.enc_out_bbox_embed.layers.2.bias": 4,
  "transformer.enc_out_class_embed.weight": 23296,
  "transformer.enc_out_class_embed.bias": 91,
  "label_enc.weight": 23552,
  "input_proj.0.0.weight": 131072,
  "input_proj.0.0.bias": 256,
  "input_proj.0.1.weight": 256,
  "input_proj.0.1.bias": 256,
  "input_proj.1.0.weight": 262144,
  "input_proj.1.0.bias": 256,
  "input_proj.1.1.weight": 256,
  "input_proj.1.1.bias": 256,
  "input_proj.2.0.weight": 524288,
  "input_proj.2.0.bias": 256,
  "input_proj.2.1.weight": 256,
  "input_proj.2.1.bias": 256,
  "input_proj.3.0.weight": 4718592,
  "input_proj.3.0.bias": 256,
  "input_proj.3.1.weight": 256,
  "input_proj.3.1.bias": 256,
  "backbone.0.downsample_layers.0.0.weight": 12288,
  "backbone.0.downsample_layers.0.0.bias": 256,
  "backbone.0.downsample_layers.0.1.weight": 256,
  "backbone.0.downsample_layers.0.1.bias": 256,
  "backbone.0.downsample_layers.1.0.weight": 256,
  "backbone.0.downsample_layers.1.0.bias": 256,
  "backbone.0.downsample_layers.1.1.weight": 524288,
  "backbone.0.downsample_layers.1.1.bias": 512,
  "backbone.0.downsample_layers.2.0.weight": 512,
  "backbone.0.downsample_layers.2.0.bias": 512,
  "backbone.0.downsample_layers.2.1.weight": 2097152,
  "backbone.0.downsample_layers.2.1.bias": 1024,
  "backbone.0.downsample_layers.3.0.weight": 1024,
  "backbone.0.downsample_layers.3.0.bias": 1024,
  "backbone.0.downsample_layers.3.1.weight": 8388608,
  "backbone.0.downsample_layers.3.1.bias": 2048,
  "backbone.0.stages.0.0.gamma": 256,
  "backbone.0.stages.0.0.dwconv.weight": 12544,
  "backbone.0.stages.0.0.dwconv.bias": 256,
  "backbone.0.stages.0.0.norm.weight": 256,
  "backbone.0.stages.0.0.norm.bias": 256,
  "backbone.0.stages.0.0.pwconv1.weight": 262144,
  "backbone.0.stages.0.0.pwconv1.bias": 1024,
  "backbone.0.stages.0.0.pwconv2.weight": 262144,
  "backbone.0.stages.0.0.pwconv2.bias": 256,
  "backbone.0.stages.0.1.gamma": 256,
  "backbone.0.stages.0.1.dwconv.weight": 12544,
  "backbone.0.stages.0.1.dwconv.bias": 256,
  "backbone.0.stages.0.1.norm.weight": 256,
  "backbone.0.stages.0.1.norm.bias": 256,
  "backbone.0.stages.0.1.pwconv1.weight": 262144,
  "backbone.0.stages.0.1.pwconv1.bias": 1024,
  "backbone.0.stages.0.1.pwconv2.weight": 262144,
  "backbone.0.stages.0.1.pwconv2.bias": 256,
  "backbone.0.stages.0.2.gamma": 256,
  "backbone.0.stages.0.2.dwconv.weight": 12544,
  "backbone.0.stages.0.2.dwconv.bias": 256,
  "backbone.0.stages.0.2.norm.weight": 256,
  "backbone.0.stages.0.2.norm.bias": 256,
  "backbone.0.stages.0.2.pwconv1.weight": 262144,
  "backbone.0.stages.0.2.pwconv1.bias": 1024,
  "backbone.0.stages.0.2.pwconv2.weight": 262144,
  "backbone.0.stages.0.2.pwconv2.bias": 256,
  "backbone.0.stages.1.0.gamma": 512,
  "backbone.0.stages.1.0.dwconv.weight": 25088,
  "backbone.0.stages.1.0.dwconv.bias": 512,
  "backbone.0.stages.1.0.norm.weight": 512,
  "backbone.0.stages.1.0.norm.bias": 512,
  "backbone.0.stages.1.0.pwconv1.weight": 1048576,
  "backbone.0.stages.1.0.pwconv1.bias": 2048,
  "backbone.0.stages.1.0.pwconv2.weight": 1048576,
  "backbone.0.stages.1.0.pwconv2.bias": 512,
  "backbone.0.stages.1.1.gamma": 512,
  "backbone.0.stages.1.1.dwconv.weight": 25088,
  "backbone.0.stages.1.1.dwconv.bias": 512,
  "backbone.0.stages.1.1.norm.weight": 512,
  "backbone.0.stages.1.1.norm.bias": 512,
  "backbone.0.stages.1.1.pwconv1.weight": 1048576,
  "backbone.0.stages.1.1.pwconv1.bias": 2048,
  "backbone.0.stages.1.1.pwconv2.weight": 1048576,
  "backbone.0.stages.1.1.pwconv2.bias": 512,
  "backbone.0.stages.1.2.gamma": 512,
  "backbone.0.stages.1.2.dwconv.weight": 25088,
  "backbone.0.stages.1.2.dwconv.bias": 512,
  "backbone.0.stages.1.2.norm.weight": 512,
  "backbone.0.stages.1.2.norm.bias": 512,
  "backbone.0.stages.1.2.pwconv1.weight": 1048576,
  "backbone.0.stages.1.2.pwconv1.bias": 2048,
  "backbone.0.stages.1.2.pwconv2.weight": 1048576,
  "backbone.0.stages.1.2.pwconv2.bias": 512,
  "backbone.0.stages.2.0.gamma": 1024,
  "backbone.0.stages.2.0.dwconv.weight": 50176,
  "backbone.0.stages.2.0.dwconv.bias": 1024,
  "backbone.0.stages.2.0.norm.weight": 1024,
  "backbone.0.stages.2.0.norm.bias": 1024,
  "backbone.0.stages.2.0.pwconv1.weight": 4194304,
  "backbone.0.stages.2.0.pwconv1.bias": 4096,
  "backbone.0.stages.2.0.pwconv2.weight": 4194304,
  "backbone.0.stages.2.0.pwconv2.bias": 1024,
  "backbone.0.stages.2.1.gamma": 1024,
  "backbone.0.stages.2.1.dwconv.weight": 50176,
  "backbone.0.stages.2.1.dwconv.bias": 1024,
  "backbone.0.stages.2.1.norm.weight": 1024,
  "backbone.0.stages.2.1.norm.bias": 1024,
  "backbone.0.stages.2.1.pwconv1.weight": 4194304,
  "backbone.0.stages.2.1.pwconv1.bias": 4096,
  "backbone.0.stages.2.1.pwconv2.weight": 4194304,
  "backbone.0.stages.2.1.pwconv2.bias": 1024,
  "backbone.0.stages.2.2.gamma": 1024,
  "backbone.0.stages.2.2.dwconv.weight": 50176,
  "backbone.0.stages.2.2.dwconv.bias": 1024,
  "backbone.0.stages.2.2.norm.weight": 1024,
  "backbone.0.stages.2.2.norm.bias": 1024,
  "backbone.0.stages.2.2.pwconv1.weight": 4194304,
  "backbone.0.stages.2.2.pwconv1.bias": 4096,
  "backbone.0.stages.2.2.pwconv2.weight": 4194304,
  "backbone.0.stages.2.2.pwconv2.bias": 1024,
  "backbone.0.stages.2.3.gamma": 1024,
  "backbone.0.stages.2.3.dwconv.weight": 50176,
  "backbone.0.stages.2.3.dwconv.bias": 1024,
  "backbone.0.stages.2.3.norm.weight": 1024,
  "backbone.0.stages.2.3.norm.bias": 1024,
  "backbone.0.stages.2.3.pwconv1.weight": 4194304,
  "backbone.0.stages.2.3.pwconv1.bias": 4096,
  "backbone.0.stages.2.3.pwconv2.weight": 4194304,
  "backbone.0.stages.2.3.pwconv2.bias": 1024,
  "backbone.0.stages.2.4.gamma": 1024,
  "backbone.0.stages.2.4.dwconv.weight": 50176,
  "backbone.0.stages.2.4.dwconv.bias": 1024,
  "backbone.0.stages.2.4.norm.weight": 1024,
  "backbone.0.stages.2.4.norm.bias": 1024,
  "backbone.0.stages.2.4.pwconv1.weight": 4194304,
  "backbone.0.stages.2.4.pwconv1.bias": 4096,
  "backbone.0.stages.2.4.pwconv2.weight": 4194304,
  "backbone.0.stages.2.4.pwconv2.bias": 1024,
  "backbone.0.stages.2.5.gamma": 1024,
  "backbone.0.stages.2.5.dwconv.weight": 50176,
  "backbone.0.stages.2.5.dwconv.bias": 1024,
  "backbone.0.stages.2.5.norm.weight": 1024,
  "backbone.0.stages.2.5.norm.bias": 1024,
  "backbone.0.stages.2.5.pwconv1.weight": 4194304,
  "backbone.0.stages.2.5.pwconv1.bias": 4096,
  "backbone.0.stages.2.5.pwconv2.weight": 4194304,
  "backbone.0.stages.2.5.pwconv2.bias": 1024,
  "backbone.0.stages.2.6.gamma": 1024,
  "backbone.0.stages.2.6.dwconv.weight": 50176,
  "backbone.0.stages.2.6.dwconv.bias": 1024,
  "backbone.0.stages.2.6.norm.weight": 1024,
  "backbone.0.stages.2.6.norm.bias": 1024,
  "backbone.0.stages.2.6.pwconv1.weight": 4194304,
  "backbone.0.stages.2.6.pwconv1.bias": 4096,
  "backbone.0.stages.2.6.pwconv2.weight": 4194304,
  "backbone.0.stages.2.6.pwconv2.bias": 1024,
  "backbone.0.stages.2.7.gamma": 1024,
  "backbone.0.stages.2.7.dwconv.weight": 50176,
  "backbone.0.stages.2.7.dwconv.bias": 1024,
  "backbone.0.stages.2.7.norm.weight": 1024,
  "backbone.0.stages.2.7.norm.bias": 1024,
  "backbone.0.stages.2.7.pwconv1.weight": 4194304,
  "backbone.0.stages.2.7.pwconv1.bias": 4096,
  "backbone.0.stages.2.7.pwconv2.weight": 4194304,
  "backbone.0.stages.2.7.pwconv2.bias": 1024,
  "backbone.0.stages.2.8.gamma": 1024,
  "backbone.0.stages.2.8.dwconv.weight": 50176,
  "backbone.0.stages.2.8.dwconv.bias": 1024,
  "backbone.0.stages.2.8.norm.weight": 1024,
  "backbone.0.stages.2.8.norm.bias": 1024,
  "backbone.0.stages.2.8.pwconv1.weight": 4194304,
  "backbone.0.stages.2.8.pwconv1.bias": 4096,
  "backbone.0.stages.2.8.pwconv2.weight": 4194304,
  "backbone.0.stages.2.8.pwconv2.bias": 1024,
  "backbone.0.stages.2.9.gamma": 1024,
  "backbone.0.stages.2.9.dwconv.weight": 50176,
  "backbone.0.stages.2.9.dwconv.bias": 1024,
  "backbone.0.stages.2.9.norm.weight": 1024,
  "backbone.0.stages.2.9.norm.bias": 1024,
  "backbone.0.stages.2.9.pwconv1.weight": 4194304,
  "backbone.0.stages.2.9.pwconv1.bias": 4096,
  "backbone.0.stages.2.9.pwconv2.weight": 4194304,
  "backbone.0.stages.2.9.pwconv2.bias": 1024,
  "backbone.0.stages.2.10.gamma": 1024,
  "backbone.0.stages.2.10.dwconv.weight": 50176,
  "backbone.0.stages.2.10.dwconv.bias": 1024,
  "backbone.0.stages.2.10.norm.weight": 1024,
  "backbone.0.stages.2.10.norm.bias": 1024,
  "backbone.0.stages.2.10.pwconv1.weight": 4194304,
  "backbone.0.stages.2.10.pwconv1.bias": 4096,
  "backbone.0.stages.2.10.pwconv2.weight": 4194304,
  "backbone.0.stages.2.10.pwconv2.bias": 1024,
  "backbone.0.stages.2.11.gamma": 1024,
  "backbone.0.stages.2.11.dwconv.weight": 50176,
  "backbone.0.stages.2.11.dwconv.bias": 1024,
  "backbone.0.stages.2.11.norm.weight": 1024,
  "backbone.0.stages.2.11.norm.bias": 1024,
  "backbone.0.stages.2.11.pwconv1.weight": 4194304,
  "backbone.0.stages.2.11.pwconv1.bias": 4096,
  "backbone.0.stages.2.11.pwconv2.weight": 4194304,
  "backbone.0.stages.2.11.pwconv2.bias": 1024,
  "backbone.0.stages.2.12.gamma": 1024,
  "backbone.0.stages.2.12.dwconv.weight": 50176,
  "backbone.0.stages.2.12.dwconv.bias": 1024,
  "backbone.0.stages.2.12.norm.weight": 1024,
  "backbone.0.stages.2.12.norm.bias": 1024,
  "backbone.0.stages.2.12.pwconv1.weight": 4194304,
  "backbone.0.stages.2.12.pwconv1.bias": 4096,
  "backbone.0.stages.2.12.pwconv2.weight": 4194304,
  "backbone.0.stages.2.12.pwconv2.bias": 1024,
  "backbone.0.stages.2.13.gamma": 1024,
  "backbone.0.stages.2.13.dwconv.weight": 50176,
  "backbone.0.stages.2.13.dwconv.bias": 1024,
  "backbone.0.stages.2.13.norm.weight": 1024,
  "backbone.0.stages.2.13.norm.bias": 1024,
  "backbone.0.stages.2.13.pwconv1.weight": 4194304,
  "backbone.0.stages.2.13.pwconv1.bias": 4096,
  "backbone.0.stages.2.13.pwconv2.weight": 4194304,
  "backbone.0.stages.2.13.pwconv2.bias": 1024,
  "backbone.0.stages.2.14.gamma": 1024,
  "backbone.0.stages.2.14.dwconv.weight": 50176,
  "backbone.0.stages.2.14.dwconv.bias": 1024,
  "backbone.0.stages.2.14.norm.weight": 1024,
  "backbone.0.stages.2.14.norm.bias": 1024,
  "backbone.0.stages.2.14.pwconv1.weight": 4194304,
  "backbone.0.stages.2.14.pwconv1.bias": 4096,
  "backbone.0.stages.2.14.pwconv2.weight": 4194304,
  "backbone.0.stages.2.14.pwconv2.bias": 1024,
  "backbone.0.stages.2.15.gamma": 1024,
  "backbone.0.stages.2.15.dwconv.weight": 50176,
  "backbone.0.stages.2.15.dwconv.bias": 1024,
  "backbone.0.stages.2.15.norm.weight": 1024,
  "backbone.0.stages.2.15.norm.bias": 1024,
  "backbone.0.stages.2.15.pwconv1.weight": 4194304,
  "backbone.0.stages.2.15.pwconv1.bias": 4096,
  "backbone.0.stages.2.15.pwconv2.weight": 4194304,
  "backbone.0.stages.2.15.pwconv2.bias": 1024,
  "backbone.0.stages.2.16.gamma": 1024,
  "backbone.0.stages.2.16.dwconv.weight": 50176,
  "backbone.0.stages.2.16.dwconv.bias": 1024,
  "backbone.0.stages.2.16.norm.weight": 1024,
  "backbone.0.stages.2.16.norm.bias": 1024,
  "backbone.0.stages.2.16.pwconv1.weight": 4194304,
  "backbone.0.stages.2.16.pwconv1.bias": 4096,
  "backbone.0.stages.2.16.pwconv2.weight": 4194304,
  "backbone.0.stages.2.16.pwconv2.bias": 1024,
  "backbone.0.stages.2.17.gamma": 1024,
  "backbone.0.stages.2.17.dwconv.weight": 50176,
  "backbone.0.stages.2.17.dwconv.bias": 1024,
  "backbone.0.stages.2.17.norm.weight": 1024,
  "backbone.0.stages.2.17.norm.bias": 1024,
  "backbone.0.stages.2.17.pwconv1.weight": 4194304,
  "backbone.0.stages.2.17.pwconv1.bias": 4096,
  "backbone.0.stages.2.17.pwconv2.weight": 4194304,
  "backbone.0.stages.2.17.pwconv2.bias": 1024,
  "backbone.0.stages.2.18.gamma": 1024,
  "backbone.0.stages.2.18.dwconv.weight": 50176,
  "backbone.0.stages.2.18.dwconv.bias": 1024,
  "backbone.0.stages.2.18.norm.weight": 1024,
  "backbone.0.stages.2.18.norm.bias": 1024,
  "backbone.0.stages.2.18.pwconv1.weight": 4194304,
  "backbone.0.stages.2.18.pwconv1.bias": 4096,
  "backbone.0.stages.2.18.pwconv2.weight": 4194304,
  "backbone.0.stages.2.18.pwconv2.bias": 1024,
  "backbone.0.stages.2.19.gamma": 1024,
  "backbone.0.stages.2.19.dwconv.weight": 50176,
  "backbone.0.stages.2.19.dwconv.bias": 1024,
  "backbone.0.stages.2.19.norm.weight": 1024,
  "backbone.0.stages.2.19.norm.bias": 1024,
  "backbone.0.stages.2.19.pwconv1.weight": 4194304,
  "backbone.0.stages.2.19.pwconv1.bias": 4096,
  "backbone.0.stages.2.19.pwconv2.weight": 4194304,
  "backbone.0.stages.2.19.pwconv2.bias": 1024,
  "backbone.0.stages.2.20.gamma": 1024,
  "backbone.0.stages.2.20.dwconv.weight": 50176,
  "backbone.0.stages.2.20.dwconv.bias": 1024,
  "backbone.0.stages.2.20.norm.weight": 1024,
  "backbone.0.stages.2.20.norm.bias": 1024,
  "backbone.0.stages.2.20.pwconv1.weight": 4194304,
  "backbone.0.stages.2.20.pwconv1.bias": 4096,
  "backbone.0.stages.2.20.pwconv2.weight": 4194304,
  "backbone.0.stages.2.20.pwconv2.bias": 1024,
  "backbone.0.stages.2.21.gamma": 1024,
  "backbone.0.stages.2.21.dwconv.weight": 50176,
  "backbone.0.stages.2.21.dwconv.bias": 1024,
  "backbone.0.stages.2.21.norm.weight": 1024,
  "backbone.0.stages.2.21.norm.bias": 1024,
  "backbone.0.stages.2.21.pwconv1.weight": 4194304,
  "backbone.0.stages.2.21.pwconv1.bias": 4096,
  "backbone.0.stages.2.21.pwconv2.weight": 4194304,
  "backbone.0.stages.2.21.pwconv2.bias": 1024,
  "backbone.0.stages.2.22.gamma": 1024,
  "backbone.0.stages.2.22.dwconv.weight": 50176,
  "backbone.0.stages.2.22.dwconv.bias": 1024,
  "backbone.0.stages.2.22.norm.weight": 1024,
  "backbone.0.stages.2.22.norm.bias": 1024,
  "backbone.0.stages.2.22.pwconv1.weight": 4194304,
  "backbone.0.stages.2.22.pwconv1.bias": 4096,
  "backbone.0.stages.2.22.pwconv2.weight": 4194304,
  "backbone.0.stages.2.22.pwconv2.bias": 1024,
  "backbone.0.stages.2.23.gamma": 1024,
  "backbone.0.stages.2.23.dwconv.weight": 50176,
  "backbone.0.stages.2.23.dwconv.bias": 1024,
  "backbone.0.stages.2.23.norm.weight": 1024,
  "backbone.0.stages.2.23.norm.bias": 1024,
  "backbone.0.stages.2.23.pwconv1.weight": 4194304,
  "backbone.0.stages.2.23.pwconv1.bias": 4096,
  "backbone.0.stages.2.23.pwconv2.weight": 4194304,
  "backbone.0.stages.2.23.pwconv2.bias": 1024,
  "backbone.0.stages.2.24.gamma": 1024,
  "backbone.0.stages.2.24.dwconv.weight": 50176,
  "backbone.0.stages.2.24.dwconv.bias": 1024,
  "backbone.0.stages.2.24.norm.weight": 1024,
  "backbone.0.stages.2.24.norm.bias": 1024,
  "backbone.0.stages.2.24.pwconv1.weight": 4194304,
  "backbone.0.stages.2.24.pwconv1.bias": 4096,
  "backbone.0.stages.2.24.pwconv2.weight": 4194304,
  "backbone.0.stages.2.24.pwconv2.bias": 1024,
  "backbone.0.stages.2.25.gamma": 1024,
  "backbone.0.stages.2.25.dwconv.weight": 50176,
  "backbone.0.stages.2.25.dwconv.bias": 1024,
  "backbone.0.stages.2.25.norm.weight": 1024,
  "backbone.0.stages.2.25.norm.bias": 1024,
  "backbone.0.stages.2.25.pwconv1.weight": 4194304,
  "backbone.0.stages.2.25.pwconv1.bias": 4096,
  "backbone.0.stages.2.25.pwconv2.weight": 4194304,
  "backbone.0.stages.2.25.pwconv2.bias": 1024,
  "backbone.0.stages.2.26.gamma": 1024,
  "backbone.0.stages.2.26.dwconv.weight": 50176,
  "backbone.0.stages.2.26.dwconv.bias": 1024,
  "backbone.0.stages.2.26.norm.weight": 1024,
  "backbone.0.stages.2.26.norm.bias": 1024,
  "backbone.0.stages.2.26.pwconv1.weight": 4194304,
  "backbone.0.stages.2.26.pwconv1.bias": 4096,
  "backbone.0.stages.2.26.pwconv2.weight": 4194304,
  "backbone.0.stages.2.26.pwconv2.bias": 1024,
  "backbone.0.stages.3.0.gamma": 2048,
  "backbone.0.stages.3.0.dwconv.weight": 100352,
  "backbone.0.stages.3.0.dwconv.bias": 2048,
  "backbone.0.stages.3.0.norm.weight": 2048,
  "backbone.0.stages.3.0.norm.bias": 2048,
  "backbone.0.stages.3.0.pwconv1.weight": 16777216,
  "backbone.0.stages.3.0.pwconv1.bias": 8192,
  "backbone.0.stages.3.0.pwconv2.weight": 16777216,
  "backbone.0.stages.3.0.pwconv2.bias": 2048,
  "backbone.0.stages.3.1.gamma": 2048,
  "backbone.0.stages.3.1.dwconv.weight": 100352,
  "backbone.0.stages.3.1.dwconv.bias": 2048,
  "backbone.0.stages.3.1.norm.weight": 2048,
  "backbone.0.stages.3.1.norm.bias": 2048,
  "backbone.0.stages.3.1.pwconv1.weight": 16777216,
  "backbone.0.stages.3.1.pwconv1.bias": 8192,
  "backbone.0.stages.3.1.pwconv2.weight": 16777216,
  "backbone.0.stages.3.1.pwconv2.bias": 2048,
  "backbone.0.stages.3.2.gamma": 2048,
  "backbone.0.stages.3.2.dwconv.weight": 100352,
  "backbone.0.stages.3.2.dwconv.bias": 2048,
  "backbone.0.stages.3.2.norm.weight": 2048,
  "backbone.0.stages.3.2.norm.bias": 2048,
  "backbone.0.stages.3.2.pwconv1.weight": 16777216,
  "backbone.0.stages.3.2.pwconv1.bias": 8192,
  "backbone.0.stages.3.2.pwconv2.weight": 16777216,
  "backbone.0.stages.3.2.pwconv2.bias": 2048,
  "backbone.0.norm0.weight": 256,
  "backbone.0.norm0.bias": 256,
  "backbone.0.norm1.weight": 512,
  "backbone.0.norm1.bias": 512,
  "backbone.0.norm2.weight": 1024,
  "backbone.0.norm2.bias": 1024,
  "backbone.0.norm3.weight": 2048,
  "backbone.0.norm3.bias": 2048
}
data_aug_params: {
  "scales": [
    480,
    512,
    544,
    576,
    608,
    640,
    672,
    704,
    736,
    768,
    800
  ],
  "max_size": 1333,
  "scales2_resize": [
    400,
    500,
    600
  ],
  "scales2_crop": [
    384,
    600
  ]
}
loading annotations into memory...
Done (t=19.06s)
creating index...
index created!
data_aug_params: {
  "scales": [
    480,
    512,
    544,
    576,
    608,
    640,
    672,
    704,
    736,
    768,
    800
  ],
  "max_size": 1333,
  "scales2_resize": [
    400,
    500,
    600
  ],
  "scales2_crop": [
    384,
    600
  ]
}
loading annotations into memory...
Done (t=0.73s)
creating index...
index created!
Start training
submitit ERROR (2022-07-15 00:28:26,065) - Submitted job triggered an exception
